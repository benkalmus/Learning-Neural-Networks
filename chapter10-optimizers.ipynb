{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10 - Optimisers - Stochastic Gradient Descent (SGD)\n",
    "\n",
    "- **The Stochastic Gradient Descent** historically refers to an optimizer that fits a single\n",
    "sample at a time. \n",
    "- **The Batch Gradient Descent**, is an optimizer used to fit a whole dataset at once. \n",
    "- **Mini-batch Gradient Descent**, is used to fit slices of a dataset, which we’d call batches in our context. \n",
    "\n",
    "\n",
    "In the context of deep learning and this book, we call *slices* of data *batches*, where,\n",
    "historically, the term to refer to slices of data in the context of Stochastic Gradient Descent was *mini-batches*. In a future chapter, we’ll introduce data slices, or batches, so we should start by using the Mini-batch Gradient Descent optimizer.\n",
    "\n",
    "\n",
    "In the case of Stochastic Gradient Descent, we choose a learning rate, such as 1.0. We then\n",
    "subtract the learning_rate · parameter_gradients from the actual parameter values.\n",
    "\n",
    "If our learning rate is 1, then we’re subtracting the exact amount of gradient from our parameters. We’re going to start with 1 to see the results, but we’ll be diving more into the learning rate shortly. Let’s create the SGD optimizer class code. The initialization method will take hyper-parameters, starting with the learning rate, for now, storing them in the class’ properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD optimizer\n",
    "class Optimizer_SGD:\n",
    "    # Initialize optimizer - set settings,\n",
    "    # learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1.0):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        weight_updates = -self.current_learning_rate * layer.dweights\n",
    "        bias_updates = -self.current_learning_rate * layer.dbiases\n",
    "        # Update weights and biases using either\n",
    "        # vanilla or momentum updates\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dense1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer_SGD()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# update our network layer’s parameters after calculating the gradient using\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mupdate_params(\u001b[43mdense1\u001b[49m)\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mupdate_params(dense2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dense1' is not defined"
     ]
    }
   ],
   "source": [
    "#The update_params method, given a layer object, multiplies the gradients stored in the layers by the negated learning rate and adds the result to the layer’s parameters.\n",
    "optimizer = Optimizer_SGD()\n",
    "# update our network layer’s parameters after calculating the gradient using\n",
    "optimizer.update_params(dense1)\n",
    "optimizer.update_params(dense2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n",
      "0.8333333333333334\n",
      "0.7692307692307692\n",
      "0.7142857142857143\n",
      "0.6666666666666666\n",
      "0.625\n",
      "0.588235294117647\n",
      "0.5555555555555556\n",
      "0.5263157894736842\n",
      "0.5\n",
      "0.47619047619047616\n",
      "0.45454545454545453\n",
      "0.4347826086956522\n",
      "0.41666666666666663\n",
      "0.4\n",
      "0.3846153846153846\n",
      "0.37037037037037035\n",
      "0.35714285714285715\n",
      "0.3448275862068965\n"
     ]
    }
   ],
   "source": [
    "# Exponential decay, 1/t\n",
    "\n",
    "starting_learning_rate = 1.\n",
    "learning_rate_decay = 0.1\n",
    "step = 1\n",
    "for step in range(1, 20, 1):\n",
    "    learning_rate = starting_learning_rate * \\\n",
    "    (1. / (1 + learning_rate_decay * step))\n",
    "    print(learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Momentum\n",
    "\n",
    "THe problem with regular SGD is that it will always roughly point in the direction of the local minimum, and this can cause us to get stuck. Adding momentum to our gradients will allow us to \"roll over\" the local minima. This is done by allowing the previous gradients to influence the outcome. We can add another hyperparameter to tune how much momentum we'd like to carry over. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters\n",
    "def update_params(self, layer):\n",
    "    # If layer does not contain momentum arrays, create them\n",
    "    # filled with zeros\n",
    "    if not hasattr(layer, 'weight_momentums'):\n",
    "        layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "        # If there is no momentum array for weights\n",
    "        # The array doesn't exist for biases yet either.\n",
    "        layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "    # Build weight updates with momentum - take previous\n",
    "    # updates multiplied by retain factor and update with\n",
    "    # current gradients\n",
    "    weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights\n",
    "    layer.weight_momentums = weight_updates\n",
    "    # Build bias updates\n",
    "    bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases\n",
    "    layer.bias_momentums = bias_updates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaGrad: Adapative Gradient \n",
    "\n",
    "Innovated on learning rate by implenting a per-parameter learning rate rather than a globally shared single value  (like above). \n",
    "The point is to normalize updates as during training neurons with smaller weights won't change much. \n",
    "AdaGrad does this by keeping a history of previous updates. This lets less-frequently\n",
    "updated parameters to keep-up with changes, effectively utilizing more neurons for training.\n",
    "\n",
    "```python\n",
    "cache += parm_gradient ** 2\n",
    "parm_updates = learning_rate * parm_gradient / (sqrt(cache) + epsilon)\n",
    "```\n",
    "\n",
    "- **cache** holds a history of squared gradients\n",
    "- **parm_updates** is a function of the learning rate multiplied by the gradient \n",
    "- **epsilon** is a hyperparameter preventing division by 0.\n",
    "\n",
    "\n",
    "We are adding squared values and taking the square root, which is not the same as just adding the value. The resulting cache value grows slower.\n",
    "\n",
    "\n",
    "Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adagrad optimizer\n",
    "class Optimizer_Adagrad:\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "        \n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "            \n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache += layer.dweights**2\n",
    "        layer.bias_cache += layer.dbiases**2\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * layer.dweights / (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases  += -self.current_learning_rate * layer.dbiases / (np.sqrt(layer.bias_cache) + self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp\n",
    "## Root Mean Square Propagation\n",
    "\n",
    "Similar to AdaGrad, cache is calculated differently\n",
    "\n",
    "```python\n",
    "cache = rho * cache + (1 - rho) * gradient**2\n",
    "```\n",
    "\n",
    "This adds a mechanism similar to momemntum, learning rate changes are smoother as we've implemented a moving average of the cache.\n",
    "New hyper parameter **rho**, is cache memory decay rate. \n",
    "\n",
    "\"Help retain global direction of changes\"\n",
    "\n",
    "Each update to the cache retains a part of\n",
    "the cache and updates it with a fraction of the new, squared, gradients. In this way, cache contents\n",
    "“move” with data in time, and learning does not stall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update parameters\n",
    "def update_params(self, layer):\n",
    "    # If layer does not contain cache arrays,\n",
    "    # create them filled with zeros\n",
    "    if not hasattr(layer, 'weight_cache'):\n",
    "        layer.weight_cache = np.zeros_like(layer.weights)\n",
    "        layer.bias_cache = np.zeros_like(layer.biases)\n",
    "    # Update cache with squared current gradients\n",
    "    layer.weight_cache = self.rho * layer.weight_cache + (1 - self.rho) * layer.dweights**2\n",
    "    layer.bias_cache = self.rho * layer.bias_cache + (1 - self.rho) * layer.dbiases**2\n",
    "    # Vanilla SGD parameter update + normalization\n",
    "    # with square rooted cache\n",
    "    layer.weights += -self.current_learning_rate * layer.dweights /  (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "    layer.biases  += -self.current_learning_rate * layer.dbiases /   (np.sqrt(layer.bias_cache) + self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam\n",
    "## Adaptive Momentum\n",
    "\n",
    "Currently the most widely used optimizer, built atop RMSProp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
